{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9b596549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from qbstyles import mpl_style\n",
    "\n",
    "mpl_style(dark=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "400ad1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8ebcccfae64f2784bf25f90f77e250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\HW files\\Learner-s-Garden\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\daith\\.cache\\huggingface\\hub\\datasets--mnist. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981f3c8be49d4a789d373c3032916a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/15.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee66cbfbc64447b799128b92e2b5dae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/2.60M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c162dab8c74b95bf3af24f5af1b627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180956cebf3f46efb66426cd14fe69be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"mnist\", split=\"train[:100]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5a9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAklEQVR4AWIY1IBZSEiormO91LL/3+tBDmUBESAsx2ZlIxAMYj2ZFPj54kEQixFEMDAwGO7lh7L+JX1lePb+JpQHBkK3/4LAsW3fP4L5qETAnOy/f89yM2jPQhWHAD7GWX+jIEwYyQRjMHz6/5EhBcGFi0MB976/blAmFkr548MFOTD3Y8gHfvj7t1wSQxgKdHf9/TtNGsrBoARi//zdjSEKBz///nSAcuBhC+HrhZiyMFw7BOGgkoCpT3n69+/fX9tQRcE8iaK7oOA96QfmoRDiTldBUscCMQNJaDU4Vg4HcKLoAHHM1zwC6frSyg3iITDYtYGBDAzXN//t+YAQpyULAEUXXoDz1Y8qAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7540e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lst = [\n",
    "    (transforms.ToTensor()(sample['image']) / 255.0, torch.tensor(sample['label']))\n",
    "    for sample in dataset\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "526f16f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lst[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f69c6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SoftmaxRegression, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77d6694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxRegression(28 * 28, 10)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "50e71e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: loss = 0.1876\n",
      "Epoch 2/100: loss = 0.1875\n",
      "Epoch 3/100: loss = 0.1874\n",
      "Epoch 4/100: loss = 0.1872\n",
      "Epoch 5/100: loss = 0.1871\n",
      "Epoch 6/100: loss = 0.1870\n",
      "Epoch 7/100: loss = 0.1869\n",
      "Epoch 8/100: loss = 0.1867\n",
      "Epoch 9/100: loss = 0.1866\n",
      "Epoch 10/100: loss = 0.1865\n",
      "Epoch 11/100: loss = 0.1864\n",
      "Epoch 12/100: loss = 0.1862\n",
      "Epoch 13/100: loss = 0.1861\n",
      "Epoch 14/100: loss = 0.1860\n",
      "Epoch 15/100: loss = 0.1859\n",
      "Epoch 16/100: loss = 0.1857\n",
      "Epoch 17/100: loss = 0.1856\n",
      "Epoch 18/100: loss = 0.1855\n",
      "Epoch 19/100: loss = 0.1854\n",
      "Epoch 20/100: loss = 0.1852\n",
      "Epoch 21/100: loss = 0.1851\n",
      "Epoch 22/100: loss = 0.1850\n",
      "Epoch 23/100: loss = 0.1849\n",
      "Epoch 24/100: loss = 0.1847\n",
      "Epoch 25/100: loss = 0.1846\n",
      "Epoch 26/100: loss = 0.1845\n",
      "Epoch 27/100: loss = 0.1844\n",
      "Epoch 28/100: loss = 0.1843\n",
      "Epoch 29/100: loss = 0.1841\n",
      "Epoch 30/100: loss = 0.1840\n",
      "Epoch 31/100: loss = 0.1839\n",
      "Epoch 32/100: loss = 0.1838\n",
      "Epoch 33/100: loss = 0.1836\n",
      "Epoch 34/100: loss = 0.1835\n",
      "Epoch 35/100: loss = 0.1834\n",
      "Epoch 36/100: loss = 0.1833\n",
      "Epoch 37/100: loss = 0.1832\n",
      "Epoch 38/100: loss = 0.1830\n",
      "Epoch 39/100: loss = 0.1829\n",
      "Epoch 40/100: loss = 0.1828\n",
      "Epoch 41/100: loss = 0.1827\n",
      "Epoch 42/100: loss = 0.1825\n",
      "Epoch 43/100: loss = 0.1824\n",
      "Epoch 44/100: loss = 0.1823\n",
      "Epoch 45/100: loss = 0.1822\n",
      "Epoch 46/100: loss = 0.1821\n",
      "Epoch 47/100: loss = 0.1819\n",
      "Epoch 48/100: loss = 0.1818\n",
      "Epoch 49/100: loss = 0.1817\n",
      "Epoch 50/100: loss = 0.1816\n",
      "Epoch 51/100: loss = 0.1815\n",
      "Epoch 52/100: loss = 0.1813\n",
      "Epoch 53/100: loss = 0.1812\n",
      "Epoch 54/100: loss = 0.1811\n",
      "Epoch 55/100: loss = 0.1810\n",
      "Epoch 56/100: loss = 0.1809\n",
      "Epoch 57/100: loss = 0.1808\n",
      "Epoch 58/100: loss = 0.1806\n",
      "Epoch 59/100: loss = 0.1805\n",
      "Epoch 60/100: loss = 0.1804\n",
      "Epoch 61/100: loss = 0.1803\n",
      "Epoch 62/100: loss = 0.1802\n",
      "Epoch 63/100: loss = 0.1800\n",
      "Epoch 64/100: loss = 0.1799\n",
      "Epoch 65/100: loss = 0.1798\n",
      "Epoch 66/100: loss = 0.1797\n",
      "Epoch 67/100: loss = 0.1796\n",
      "Epoch 68/100: loss = 0.1795\n",
      "Epoch 69/100: loss = 0.1793\n",
      "Epoch 70/100: loss = 0.1792\n",
      "Epoch 71/100: loss = 0.1791\n",
      "Epoch 72/100: loss = 0.1790\n",
      "Epoch 73/100: loss = 0.1789\n",
      "Epoch 74/100: loss = 0.1788\n",
      "Epoch 75/100: loss = 0.1786\n",
      "Epoch 76/100: loss = 0.1785\n",
      "Epoch 77/100: loss = 0.1784\n",
      "Epoch 78/100: loss = 0.1783\n",
      "Epoch 79/100: loss = 0.1782\n",
      "Epoch 80/100: loss = 0.1781\n",
      "Epoch 81/100: loss = 0.1780\n",
      "Epoch 82/100: loss = 0.1778\n",
      "Epoch 83/100: loss = 0.1777\n",
      "Epoch 84/100: loss = 0.1776\n",
      "Epoch 85/100: loss = 0.1775\n",
      "Epoch 86/100: loss = 0.1774\n",
      "Epoch 87/100: loss = 0.1773\n",
      "Epoch 88/100: loss = 0.1772\n",
      "Epoch 89/100: loss = 0.1770\n",
      "Epoch 90/100: loss = 0.1769\n",
      "Epoch 91/100: loss = 0.1768\n",
      "Epoch 92/100: loss = 0.1767\n",
      "Epoch 93/100: loss = 0.1766\n",
      "Epoch 94/100: loss = 0.1765\n",
      "Epoch 95/100: loss = 0.1764\n",
      "Epoch 96/100: loss = 0.1762\n",
      "Epoch 97/100: loss = 0.1761\n",
      "Epoch 98/100: loss = 0.1760\n",
      "Epoch 99/100: loss = 0.1759\n",
      "Epoch 100/100: loss = 0.1758\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=3)\n",
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    dataset_loss = 0\n",
    "    model.train()\n",
    "    for x, y in data_lst:\n",
    "        yhat = model.forward(x.reshape(-1, 28 * 28))\n",
    "        loss = criterion(yhat, y.reshape(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        dataset_loss += loss.item()\n",
    "    losses.append(dataset_loss / len(dataset))\n",
    "    print(f\"Epoch {epoch}/{epochs}: loss = {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ca7eee91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data_lst[1][0].reshape(-1, 28 * 28)).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "10f2a291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lst[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e4622814",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7290ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = parameters\n",
    "\n",
    "Image.fromarray(weights[9].reshape(28, 28).detach().numpy()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f49b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
