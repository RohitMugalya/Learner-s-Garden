{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea720210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Grayscale\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.style.use(\"../mpl styles/dracula.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ec8c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../sample img data/fire-ice fist.jpeg',\n",
       " '../sample img data/Mickey-Mouse.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [\"../sample img data/fire-ice fist.jpeg\", \"../sample img data/Mickey-Mouse.png\"]\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45b71ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, transform=None):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "        self.length = len(images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = images[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8e94f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Compose([\n",
    "    Image.open,\n",
    "    Resize((128, 128)),\n",
    "    Grayscale(),\n",
    "    ToTensor(),\n",
    "    torch.flatten,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac5769f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0118, 0.0118, 0.0118,  ..., 0.5020, 0.5137, 0.5255])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "image_dataset = ImageDataset(images, preprocess)\n",
    "for image in image_dataset:\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73cb43d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "x[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366804ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
